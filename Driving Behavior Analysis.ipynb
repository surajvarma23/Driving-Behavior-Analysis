{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df8ca85a-f46d-4d96-83d6-fe29e860d803",
   "metadata": {},
   "source": [
    "# Assignment 5\n",
    "\n",
    "## Driving Behavior Analysis\n",
    "\n",
    "### Authored by:\n",
    "Ganti Uday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ed1a9a-e40c-42c1-9f67-4a6789c15709",
   "metadata": {},
   "source": [
    "### Introduction and Overview\n",
    "\n",
    "Road rage is a very common occurance. In a survay conducted in 2019 it was revealed that 82% of the participants have commited an act of road rage in the past year. Shockingly, close to over 200 murders adn more than 12 thousand injuries and 218 murders have been attributed to road rage over the last 7 years in the United States alone. Most of these incidents occur due to drivers with impaired judgements either speedding, accelerating or breaking too quickly, or swirving in one directon too abruptly.\n",
    "\n",
    "This data includes the measures of acceleration in either X,Y or Z axis from an accelerometer, the readings of a gyroscope sensor and timestamp.\n",
    "\n",
    "This dataset was taken from Kaggle. It can be found at \"https://www.kaggle.com/datasets/outofskills/driving-behavior\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2122dc7a-aee5-40d0-9d80-b2f1db4b42e1",
   "metadata": {},
   "source": [
    "### Installation and import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63db0666-14e2-43ed-b189-8037a2f1e174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Uday Ganti\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import  confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a54f18a-10d9-48ab-adbc-4c542fd0bd0d",
   "metadata": {},
   "source": [
    "### Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6a51e2e-07cf-4f00-aa54-8f111f890b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae938d1a-557c-4578-ac91-b664fb0f5661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       AccX      AccY      AccZ     GyroX     GyroY     GyroZ       Class  \\\n",
      "0  0.758194 -0.217791  0.457263  0.000000  0.000000  0.000000  AGGRESSIVE   \n",
      "1  0.667560 -0.038610  0.231416 -0.054367 -0.007712  0.225257  AGGRESSIVE   \n",
      "2  2.724449 -7.584121  2.390926  0.023824  0.013668 -0.038026  AGGRESSIVE   \n",
      "3  2.330950 -7.621754  2.529024  0.056810 -0.180587 -0.052076  AGGRESSIVE   \n",
      "4  2.847215 -6.755621  2.224640 -0.031765 -0.035201  0.035277  AGGRESSIVE   \n",
      "\n",
      "   Timestamp  \n",
      "0     818922  \n",
      "1     818923  \n",
      "2     818923  \n",
      "3     818924  \n",
      "4     818924  \n",
      "Index(['AccX', 'AccY', 'AccZ', 'GyroX', 'GyroY', 'GyroZ', 'Class',\n",
      "       'Timestamp'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"motion_data.csv\")\n",
    "print(df.head())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8b96a48-1728-4832-93f3-effc7608bbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccX</th>\n",
       "      <th>AccY</th>\n",
       "      <th>AccZ</th>\n",
       "      <th>GyroX</th>\n",
       "      <th>GyroY</th>\n",
       "      <th>GyroZ</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.758194</td>\n",
       "      <td>-0.217791</td>\n",
       "      <td>0.457263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>AGGRESSIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.667560</td>\n",
       "      <td>-0.038610</td>\n",
       "      <td>0.231416</td>\n",
       "      <td>-0.000949</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>AGGRESSIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.724449</td>\n",
       "      <td>-7.584121</td>\n",
       "      <td>2.390926</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>-0.000664</td>\n",
       "      <td>AGGRESSIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.330950</td>\n",
       "      <td>-7.621754</td>\n",
       "      <td>2.529024</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>-0.003152</td>\n",
       "      <td>-0.000909</td>\n",
       "      <td>AGGRESSIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.847215</td>\n",
       "      <td>-6.755621</td>\n",
       "      <td>2.224640</td>\n",
       "      <td>-0.000554</td>\n",
       "      <td>-0.000614</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>AGGRESSIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AccX      AccY      AccZ     GyroX     GyroY     GyroZ       Class\n",
       "0  0.758194 -0.217791  0.457263  0.000000  0.000000  0.000000  AGGRESSIVE\n",
       "1  0.667560 -0.038610  0.231416 -0.000949 -0.000135  0.003931  AGGRESSIVE\n",
       "2  2.724449 -7.584121  2.390926  0.000416  0.000239 -0.000664  AGGRESSIVE\n",
       "3  2.330950 -7.621754  2.529024  0.000992 -0.003152 -0.000909  AGGRESSIVE\n",
       "4  2.847215 -6.755621  2.224640 -0.000554 -0.000614  0.000616  AGGRESSIVE"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"GyroX\"] = np.radians(df[\"GyroX\"])\n",
    "df[\"GyroY\"] = np.radians(df[\"GyroY\"])\n",
    "df[\"GyroZ\"] = np.radians(df[\"GyroZ\"])\n",
    "\n",
    "df = df.drop(columns = [\"Timestamp\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc2fbbb-8d86-4455-a528-74e327e6e176",
   "metadata": {},
   "source": [
    "The reason for the removal of the timestamp variable is subjective. We felt that it is not a very unrelyable variable which isn't a factor for roadrage when evaluated logically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5af64a9d-6def-401f-a186-acca2170c0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AccX     0\n",
       "AccY     0\n",
       "AccZ     0\n",
       "GyroX    0\n",
       "GyroY    0\n",
       "GyroZ    0\n",
       "Class    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dea5d0f-0958-43e9-925c-dfd405e3684a",
   "metadata": {},
   "source": [
    "### Encoding and Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc92ee4-802f-4751-8cb3-91674f666f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class']=df['Class'].astype('category')\n",
    "\n",
    "enc = LabelEncoder() \n",
    "df['Class']=enc.fit_transform(df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a681a23e-62ee-4edb-93ba-4ddbe2ae6521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    2604\n",
       "1    2197\n",
       "0    1927\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pd.unique(df['Class']))\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06e5762-d24f-4963-9a6e-69a42eaf8a39",
   "metadata": {},
   "source": [
    "### Spliting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6b6a715-0d39-4803-9ff3-f585f3be2c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1927\n",
       "1    1927\n",
       "2    1927\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'Class'\n",
    "\n",
    "predictors = list(df.columns)\n",
    "predictors.remove(target)\n",
    "\n",
    "X=df[predictors]\n",
    "y=df[target]\n",
    "\n",
    "\n",
    "rus = RandomUnderSampler(random_state=1)\n",
    "X_res, y_res = rus.fit_resample(X, y)\n",
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c11b32e0-2c38-4f54-a43a-d83f34dc70d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e99a6e4-699f-4d02-8cb0-771daa8310d4",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f77b2daf-1002-448d-b923-4b70ce5d2640",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_X)\n",
    "X_train = scaler.transform(train_X)\n",
    "X_test = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2400de33-1380-42fc-880c-f40955d147b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.44022170027368457\n",
      "parameters:  {'metric': 'euclidean', 'n_neighbors': 127}\n"
     ]
    }
   ],
   "source": [
    "score_measure = 'accuracy'\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = int(len(train_y)**(1/2)), metric='euclidean')\n",
    "knn.fit(train_X, train_y)\n",
    "y_pred = knn.predict(test_X)\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': list(range(1,(76*2),2)),\n",
    "    'metric': ['euclidean', 'cosine']\n",
    "}\n",
    "gridSearch = GridSearchCV(KNeighborsClassifier(), param_grid, scoring=score_measure,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "gridSearch.fit(train_X, train_y)\n",
    "print(score_measure, 'score: ', gridSearch.best_score_)\n",
    "print('parameters: ', gridSearch.best_params_)\n",
    "\n",
    "KNNAccuracy = gridSearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "347aba5f-b76b-4204-9a91-c173d3008aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[168, 100, 317],\n",
       "       [ 78, 135, 445],\n",
       "       [ 56, 150, 570]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1225c18c-f0e1-44d9-908f-bfd38a085f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.29      0.38       585\n",
      "           1       0.35      0.21      0.26       658\n",
      "           2       0.43      0.73      0.54       776\n",
      "\n",
      "    accuracy                           0.43      2019\n",
      "   macro avg       0.44      0.41      0.39      2019\n",
      "weighted avg       0.44      0.43      0.40      2019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a295b5-607c-46ca-b095-125c9303b6f2",
   "metadata": {},
   "source": [
    "#### Analysis:\n",
    "\n",
    "The highest accuracy of '44.02%' was generated with a k-value of 127. Although this is a reasonably low, it can be attributed to the quality of data provided. More comprehensive data with more variables could have provided a more accurate model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba1e3d1-c5a9-42c8-a019-26d6526b9223",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65b58da3-92c5-4d18-99e1-e465c30a2b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.43172755188837825\n",
      "parameters:  {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 10}\n"
     ]
    }
   ],
   "source": [
    "score_measure = 'accuracy'\n",
    "\n",
    "dtree=DecisionTreeClassifier(random_state=random_seed)\n",
    "_ = dtree.fit(train_X, train_y)\n",
    "\n",
    "y_pred = dtree.predict(test_X)\n",
    "\n",
    "param_grid = { \n",
    "              'max_depth': [2, 5, 10, 20, 30, 40],\n",
    "              'min_samples_split': [6, 10,20],       \n",
    "              'min_samples_leaf': [1, 3,  4]\n",
    "              }\n",
    "gridSearch = GridSearchCV(DecisionTreeClassifier(random_state=1), param_grid, scoring=score_measure,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "gridSearch.fit(train_X, train_y)\n",
    "print(score_measure, 'score: ', gridSearch.best_score_)\n",
    "print('parameters: ', gridSearch.best_params_)\n",
    "\n",
    "DTreeAccuracy = gridSearch.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1327fff4-5f7f-4e0b-b1ff-abd208b23b62",
   "metadata": {},
   "source": [
    "#### Analysis:\n",
    "\n",
    "Even with hyperparameter tuning parameters like max_depth, min_samples_leaf and min_samples_split, the accuracy was only '43.17'. The difference between the different observations is minute. The data present is not a good fit for the decision model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705a8746-75be-47a8-bb6e-11996264c386",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9a862ef-cb73-45a9-9864-8a67d438438f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.4502015969820244\n",
      "parameters:  {'max_depth': 8, 'min_impurity_decrease': 0.0003, 'min_samples_split': 60}\n"
     ]
    }
   ],
   "source": [
    "score_measure = 'accuracy'\n",
    "\n",
    "\n",
    "rforest = RandomForestClassifier(random_state=random_seed)\n",
    "_ = rforest.fit(train_X, train_y)\n",
    "\n",
    "y_pred = rforest.predict(test_X)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [2,5,3,4,7,8], \n",
    "    'min_samples_split': [20,30, 40,50, 60], \n",
    "    'min_impurity_decrease': [ 0.001, 0.0005, 0.0007,0.0003], \n",
    "}\n",
    "gridSearch = GridSearchCV(RandomForestClassifier(random_state=random_seed), param_grid, scoring=score_measure,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "gridSearch.fit(train_X, train_y)\n",
    "print(score_measure, 'score: ', gridSearch.best_score_)\n",
    "print('parameters: ', gridSearch.best_params_)\n",
    "\n",
    "RandomForestAccuracy = gridSearch.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd2632e-1564-42f7-a807-e0799e00fd11",
   "metadata": {},
   "source": [
    "#### Analysis:\n",
    "\n",
    "Random forest gave us the accuracy of '45.02%' which is the highest among all the other models that were run. The data quality is questionable so this the best that can be done with the defaule n_estimators and the other hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd1098a-a61f-46f2-8ec8-65f1435f448f",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e717d88-ae8e-4f31-b2b3-3bc2b5f394b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.44043491700341375\n",
      "parameters:  {'n_estimators': 5}\n"
     ]
    }
   ],
   "source": [
    "score_measure = 'accuracy'\n",
    "\n",
    "\n",
    "aboost = AdaBoostClassifier(random_state=random_seed)\n",
    "_ = aboost.fit(train_X, train_y)\n",
    "y_pred = aboost.predict(test_X)\n",
    "\n",
    "\n",
    "param_grid = { \n",
    "              'n_estimators':[5,20,50,100],\n",
    "              }\n",
    "\n",
    "gridSearch = GridSearchCV(AdaBoostClassifier(random_state=random_seed), param_grid, scoring=score_measure,\n",
    "                          n_jobs=-1)\n",
    "gridSearch.fit(train_X, train_y)\n",
    "print(score_measure, 'score: ', gridSearch.best_score_)\n",
    "print('parameters: ', gridSearch.best_params_)\n",
    "\n",
    "AdaAccuracy = gridSearch.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cd2353-8b32-4585-9081-32b4b51afb01",
   "metadata": {},
   "source": [
    "#### Analysis:\n",
    "\n",
    "This model performs better for data that creates weak learners. It still generated an accuracy score of '44.04%'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92d937e-dfb4-4b33-b5b2-19399c9ea8f6",
   "metadata": {},
   "source": [
    "## GradientBoosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0925d977-bcfd-4c90-a026-07713996c0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.4423489037952578\n",
      "parameters:  {'learning_rate': 0.2, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "score_measure = 'accuracy'\n",
    "\n",
    "\n",
    "gboost = GradientBoostingClassifier(random_state=random_seed)\n",
    "_ = gboost.fit(train_X, train_y)\n",
    "y_pred = gboost.predict(test_X)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': (3,5,10),\n",
    "    'learning_rate': (0.1,0.2,0.3,0.4,0.5)\n",
    "}\n",
    "gridSearch = GridSearchCV(GradientBoostingClassifier(random_state=random_seed), param_grid, scoring=score_measure,\n",
    "                          n_jobs=-1)\n",
    "gridSearch.fit(train_X, train_y)\n",
    "print(score_measure, 'score: ', gridSearch.best_score_)\n",
    "print('parameters: ', gridSearch.best_params_)\n",
    "\n",
    "GBoostAccuracy = gridSearch.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6b82d6-a7a2-4c0a-9e89-70a6cf139437",
   "metadata": {},
   "source": [
    "#### Analysis:\n",
    "\n",
    "In Gradient Boosting, lower learning_rate usually requires higher number of n_estimators. It stayed with the default value of 10 inthis case though.\n",
    "With this, it generated the accuracy score of '44.23%'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e9acb2-eefa-44e8-99d4-49a1c73142f8",
   "metadata": {},
   "source": [
    "## XGBoosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "315da7e4-8e8b-494f-85c9-55663dd5f7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:52:58] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Uday Ganti\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Uday Ganti\\anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "C:\\Users\\Uday Ganti\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Uday Ganti\\anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:53:20] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy score:  0.44447204604578855\n",
      "parameters:  {'learning_rate': 0.1, 'max_depth': 2, 'max_leaves': 1}\n"
     ]
    }
   ],
   "source": [
    "score_measure = 'accuracy'\n",
    "\n",
    "\n",
    "xgboost = XGBClassifier(random_state=random_seed)\n",
    "_ = xgboost.fit(train_X, train_y)\n",
    "y_pred = xgboost.predict(test_X)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': (1,2,3),\n",
    "    'max_leaves': (1,2,3,4),\n",
    "    'learning_rate': (0.1,0.15,0.05),\n",
    "}\n",
    "gridSearch = GridSearchCV(XGBClassifier(random_state=random_seed), param_grid, scoring=score_measure,\n",
    "                          n_jobs=-1)\n",
    "gridSearch.fit(train_X, train_y)\n",
    "print(score_measure, 'score: ', gridSearch.best_score_)\n",
    "print('parameters: ', gridSearch.best_params_)\n",
    "\n",
    "XGBoostAccuracy = gridSearch.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb33fab-609e-4aee-abe9-25d57e3d2cc4",
   "metadata": {},
   "source": [
    "#### Analysis:\n",
    "\n",
    "XGBoost Classifier is a very powerful modeling technique which uses advanced ML algoritms to create extremely effective and accurate models. It's limitation is that it needs atleast a reasonable amount of data and variables to provide quality outputs.\n",
    "The model was fit with a learning_rate of 0.1, max_depth of 2 and max_leaves of 1.\n",
    "\n",
    "Here, with the data it was provided, it created a model with an accuracy score of '44.44%'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "864194a2-0e34-4119-af74-dbd38f302c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model Accuracy = 0.44022170027368457)\n",
      "Decision Tree Accuracy = 0.43172755188837825\n",
      "Random Forest Accuracy = 0.4502015969820244\n",
      "AdaBoost Accuracy = 0.44043491700341375\n",
      "Gradient Boost Accuracy = 0.4423489037952578\n",
      "XG Boost Accuracy: = 0.44447204604578855\n"
     ]
    }
   ],
   "source": [
    "print(f\"KNN Model Accuracy = {KNNAccuracy})\")\n",
    "print(f\"Decision Tree Accuracy = {DTreeAccuracy}\")\n",
    "print(f\"Random Forest Accuracy = {RandomForestAccuracy}\")\n",
    "print(f\"AdaBoost Accuracy = {AdaAccuracy}\")\n",
    "print(f\"Gradient Boost Accuracy = {GBoostAccuracy}\")\n",
    "print(f\"XG Boost Accuracy: = {XGBoostAccuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd688c4-f11f-49cc-8eea-d8c8f7d3e244",
   "metadata": {},
   "source": [
    "### Reason for choosing 'Accuracy' as the metric to evaluate the models:\n",
    "\n",
    "In this case, TP & TN are self explainatory. They are accurate precictions of driving behavior. \n",
    "\n",
    "With FP & FN, the model incorrectly assumes the driver is driving slowly or normally, when they are actually driving aggressively (and the other 2 combinations of this senario).\n",
    "\n",
    "Here, FP and FN are equally dangerous and one of them isn't less important than the other. The data is also balanced. Hence, \"accuracy\" is the ideal metric to measure model quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84549212-0968-464c-9720-785ada634c61",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "There is a common trend that can be seen throughout our analysis of all the model. The quality of data in the dataset is not very good. The reason for this is that all this data was collected from a smartphone present in the car during the drive. There were no specialized equipment to take these readings.\n",
    "\n",
    "As smartphones are how alerts will be sent to the driver if they have an incident of road rage this seems like an unavoidable compromise. That said, modern cars are being equiped with more accurate and relyable hardware which will providde more variety of data which will certainly improve the output we generate through each model.\n",
    "\n",
    "In the end, Random Forest Classifer model was the model that we felt was was best fit for this data as it has the highest accuracy score compared to the rest with an accuracy score of '45.02%'. The average accuracy score for all the models combined was close to 44%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
